\documentclass[journal]{IEEEtran}
\usepackage[utf8]{inputenc}

\usepackage[sorting=none]{biblatex}
\addbibresource{bibliography.bib}


\begin{document}

\markboth{Cognitive Computing - What You Need to Know, October~2017}%
{Cognitive Computing - What You Need to Know, October~2017}

\title{Cognitive Computing - What You Need to Know}
\author{Laura~Forde,~\IEEEmembership{BSc (Hons) Software Development, Galway Mayo Institute of Technology}% 
}
% Author - Laura Forde
% This literature review is for the Research Method module that is part of my Software Development course in the Galway Mayo Institute of Technology

\maketitle


\begin{abstract}
Technology of all kinds plays a major role in society today, from mobile phones to laptops, we are constantly surrounded by it. The advancements that have been made in the last number of decades has been phenomenal. Now we are seeing systems develop even further and we are now training them to be just like the human race. Cognitive computing has been around for many years but now it is becoming a very real and possibly relied upon part of our lives. Cognitive systems may have been developed at the start for just playing games like chess and taking part in Jeopardy but now it is merging into the medical field. We are just seeing the start of cognitive systems so one must educate themselves on where this technology has come from and where it may possibly go in the future.
\end{abstract}



\section{Introduction}
One must be aware of the advancements that have been made in the technology sector over the past sixty of years, since the term Artificial Intelligence was first introduced \cite{IBMResearch}. The technologies that are being developed are simultaneously exciting and terrifying. A.I. has made significant advancements in many sectors such as the medical industry\cite{WellPointIBM} and the automotive industry as we have encountered both patient illness prediction and recommendation on treatment, as well as autonomous vehicles including consumer cars and delivery trucks\cite{auto}. Will these technologies go too far? How much of an impact will they have on us? Will these systems make us all redundant? Will we rely on them every day to do the easiest of tasks? Some may find that exciting, others will be petrified. The main question, will we push these technologies too far and use them for bad rather than good? These are the types of questions one must ask.

This review is made to give you a brief understanding of what cognitive computing is, how it came about, where it has been used already and where it may be used in the future. The aim of this review is to discuss the impact these systems will have on everyday life, on personal lives and the world as a whole. To educate people on just how powerful these systems are and to be excited for the future but also very wary of their abilities. We will discuss cognitive computing in the medical and education sectors but first we will give a brief history to understand how this technology came about.

\subsection{History}
It began back in 1950 with Alan Turing introducing the idea of the Turing test\cite{turing}. This tested computers to see if they exhibited "intelligent" behaviour. Three parties, one of which would be a computer, would be in three different locations and would be asked a series of text based questions, to see if a computer could exhibit intelligent behaviour. This was the start of what we call today, artificial intelligence. Decade by decade small but very import advancements were made in computing systems such as in the 1960's when we saw the first commercial database used for the Apollo Moon Mission by storing a vast amount of structured data that was needed for the mission. By the 1970's the concentration moved to A.I. with the first local area network from the National Physical Laboratory in England which enabled the concept of packet switching\cite{packet}. This was implemented by Donald Davies, the designer and director of this network, from NPL. In the early years of this decade the NPL local area network was connected to a similar network, ARPANET, in the United States. We also saw the doctoral dissertation of Edward Shortliffe the MYCIN system that screened blood to look for the presence of harmful bacteria that caused infection such as meningitis. Not only would this system find and harmful bacteria it also would give treatment recommendation and dosage based on the patient's weight. The system asked the physician a series of yes or no questions as well as text based questions for further knowledge of the patient. While this system was never used in the industry, even though in research it proposed acceptable treatment in sixty nine percent of cases, it paved the way for the development of such systems that could be used to help in situation where it could take humans weeks to come to possible conclusions.

Moving from A.I., the focus in the 1980's was on machine learning and Judea Pearl brought to light the probability and decision theory that is needed for a machine to "learn"\cite{judea}. Focusing on the algorithms that a computer would need to process all the data that would be needed, how to store it and then how to search through the data in a timely fashion led to many breakthroughs for systems in the following decade. That is when the first example of a cognitive computer was shown to the public, an IBM system by the name of DeepBlue, who played chess and in time beat the world champion\cite{DeepBlue}. This system was introduced in 1996 but was retired the following year. It paved the path for IBM into such systems and in 2008, after two years of production by David Ferrucci and a team of fifteen people, IBM Watson came alive. Watson was created firstly to part take in the game show Jeopardy against Ken Jennings and Brad Rutter. Watson stores all its data, that is taken in from a variety of sources such as encyclopaedias, thesauri, databases and articles to name a few, on the system RAM for a quicker response time than there would be if the data was stored on the hard drive. If it was stored on the hard drive it would not have met its end goal of winning the game show as it would have taken the system too long to access and process the data. Watson has now gone beyond its goal at the time of production as it is now being incorporated in the medical field. We will discuss later in more depth on what the Watson system really is and where the future for this system may lead. Firstly, we need a better understanding of what these systems are actually made up of.


\section{What is Cognitive Computing?}
Cognitive computing can be described as three different study sectors in one; neuroscience, supercomputing and nanotechnology\cite{whatiscc}. The aim of these systems is to understand the human brain and mimic their activity, to be able to understand speech, process what is being said and know how to answer what has been said. Not only is it made up of these three primary sectors it also includes machine learning, artificial intelligence, natural language processing, speech, vision and computer/human interaction.

\subsection{Neuroscience}
Neuroscience is the study of the nervous system and the brain. It looks at the structure and function of the nervous system and the brain. How does this relate to cognitive computing? Neuroscientists aim to discover the neural mechanisms that implement the computational process, meaning they want a computer process that will work the same way as the brain, to achieve the same outcome\cite{neuro}. We now live in a world where everything we know, we expect to somehow be part of some technology. For developers to understand what they need from a system they must have a knowledge of the parts that are needed to make up this system. Neuroscience has been around for decades and now we are seeing this become a part of the cognitive era. We have seen this be implemented by a number of systems IBM's DeepBlue\cite{DeepBlue}, the chess playing system and IBM's Watson, a system that won the game show Jeopardy by answering questions\cite{watsonAnswer} and also had coherent conversations with people.

\subsection{Supercomputers}
A super computer is a computer system but process so much more than average system. These computers can handle vast amounts of data at once. The performance of these systems are measured in FLOPS, (floating-point operations per second) and it is believed that current supercomputers can perform one hundred quadrillion FLOPS. This links in to cognitive computer as a very fast and efficient system is required. The aim is to have these systems process data like the human brain, as fast as the human brain and have an answer or response as fast as possible. For a system like this to run it must have a strong hardware behind it. Not only does the computer have to sort through data which can be held in many different forms, if it is asked a question it must build an answer that will be understandable to humans. These machines are becoming more available and we will more than likely see them all around us, maybe even own one in the future with the advances that are being made in the field\cite{super}.

\subsection{Nanotechnology}
Nanotechnology deals with the manipulation of individual atoms and molecules that are between 1 and 100 nanometers. In a cognitive system this deals with the memory, which is a primary deciding factor in the architecture of a system. It makes the system smaller as it is dealing with nanometers but does not take away from the power of the actual system\cite{nano}.


\section{IBM Watson}
As mentioned before, Watson is a prime example of what a cognitive computer is and where this technology may be heading in the future with the advancements the system has made since its unveiling in 2011. The hardware of this system is vast, compromising of a cluster of ninety IBM POWER7 50 servers, each of which have 3.5GHZ POWER7 processor threads and sixteen terabytes of RAM\cite{power}. This allows for large amounts of data to be stored and processed at ease with such power involved and allows for fast result times on processes that may be given to the processor. With regards to software, Watson is written in Java, C++ and Prolong. To allow for distributed computing, Watson uses the Apache Hadoop framework\cite{hadoop}. This is all run on the SUSE Linux Enterprise server operating system and also has the DeepQA and Apache UIMA (Unstructured Information Management Architecture). To process natural language Watson runs hundreds of proven natural language analysis algorithms simultaneously to search data on the system and find the answer that is best suited to what is being asked of it. While Watson was built primarily to take part in Jeopardy, IBM are now in partnership with WellPoint Inc. to expand Watsons use into the medical field.

\subsection{Watson and Medicine}
Similar to the MYCIN system that was mentioned in section 1-A, Watson is now going to be used for lung cancer research and assisting physicians and nurses\cite{WellPointIBM}. Watson will screen bloods and suggest treatments for the ill and recommend the dosage of a certain medicine that the patient should be administered based on weight. Not only will it greatly help the patient by giving a treatment recommendation within seconds it will also help physicians who could take weeks to sort through all the data to find the best treatment for a certain patient.

\section{The Future of Cognitive Computing}
Based on the research that IBM have conducted and are still carrying out, one must be hopeful for the future of these powerful computer systems. Other companies are now expanding into the cognitive era, following in IBM's footsteps, each research team may develop very different thoughts and projects from others\cite{hp}. This is the reason for so many different adaptations of the same technology. One must keep note of how these systems are developing and where they are being implemented. The future is bright, exciting and very hopeful for cognitive computers, with the possibility of being put to such good use in the medical field and many other sectors in years to come. While it is very exciting, it could also be very concerning. Will these computer systems make humans redundant? Will our only purpose in this world will be to keep these systems running while they do everything around us? Systems such as these can be used for a variety of things in everyday life, maybe we will see an education system free of human teachers or lecturers, replaced by cognitive computers educating and interacting with students, much like how Watson can hold a conversation and answer questions within seconds.

\subsection{How Could This Affect Humans}
The advantages of cognitive computing are infinite. Not only is it now being used for medical purposes it may also venture further into our lives and could possibly make it into our education system\cite{education}. One must embrace the advantages systems such as Watson will bring to society - these systems may save hundreds, if not thousands, of lives and may play an important role in the research into cancer treatments. 

\subsection{Current Difficulties}
While cognitive computers are undeniably amazing and have many uses, many still to be revealed in the future, it can be difficult to use these systems. The hardware that is needed for the running of these systems is vast and cannot physically be moved with much ease. Watson's hardware is an example of how difficult it would be to move a system, as it has a cluster of ninety servers to run software required\cite{power}. Research is being carried out into cloud servers, but one would be doubtful if a cloud server can be relied upon with the large amounts of data, and the problem of additionally having a good, reliable internet connection to run any process on the system.

\section{Conclusion}
While technology has come a long way, especially with the introduction of systems like Watson, there is still a long road for these systems, such as, how to make them faster, more powerful, use more data. The world is becoming aware of how powerful these systems are and how much like humans these systems are becoming. Maybe in the near or distant future a Turing test will be conducted but all parties involved will be cognitive computers with no humans in the test process. These systems have been thought about for many years, for example in 1950, when Alan Turing posed the question, “Are there imaginable digital computers which would to do well in the imitation game?”. From there, algorithms have been developed, servers that can handle very large amounts of data have been manufactured and some ideas of what these systems could possibly achieve have come to light. Cognitive computers are astonishing regarding what they can achieve but for them to be used more widely and regularly they be faced with major hurdles to overcome, for this to become a reality. What will they do in terms of cloud computing? How can it be assured that if the system moves to cloud serving that it will still have the same functions in the same response time? One must anticipate the involvement of these systems in society. It is an exciting future but also maybe a scary time as we will see how far these systems can be pushed.


\printbibliography
\end{document}